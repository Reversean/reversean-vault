Artificial intelligence (AI) **has become one of the most transformative technologies** of our time. On the positive side, it **is being applied** in medicine to detect diseases earlier, in education to personalize learning, and in industry to optimize production. These applications **have already demonstrated** how AI **can improve** efficiency and provide solutions that were previously unattainable.

At the same time, AI **carries several risks**. Algorithms **may reproduce** human biases if they **are trained** on unbalanced data, and autonomous systems **can make** decisions that **are difficult to explain**. Moreover, the increasing use of AI in surveillance **raises concerns** about privacy, while automation **might reduce** employment in certain sectors. If these risks **are not carefully managed**, they **will undermine** public trust.

Computational research itself **is evolving alongside** AI. High-performance computing **has enabled** the training of massive models that **could not have been processed** before. However, this progress **is accompanied** by growing demands for energy and the need for transparent evaluation methods. Scientists and policymakers **are therefore encouraged** to cooperate in setting standards that ensure responsible development.

AI **should be regarded** neither as a universal solution nor as an inevitable threat. Instead, it **will bring benefits if it is guided** by ethical principles, public debate, and continuous scientific oversight.