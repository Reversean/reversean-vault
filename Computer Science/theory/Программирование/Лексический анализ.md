---
aliases:
  - токенизация
  - tokenizing
---
Этап [[Компилятор#^55060a|компиляции]], преобразующий поток символов [[Исходный код|исходного кода]] в поток *лексем* (*токенов*).

Как правило, лексический анализ производится относительно [[Формальный язык|формального языка]]. В таких случаях лексический анализатор является [[Конечный автомат|конечным автоматом]], определяемого [[Множество|множеством]] [[Регулярное выражение|регулярных выражений]], определяющих этот язык.

**Лексемой** является [[Слово|словом]] на языке анализируемого текста с определенным смыслом.

Обычно к лексеме привязывается название, наделяющее ее смыслом, и, опционально, значение.

**Примеры лексем**:

| Имя лексемы  | Определение                                     | Примеры                 |
| ------------ | ----------------------------------------------- | ----------------------- |
| `identifier` | Наименование чего-либо                          | `x`, `color`            |
| `keyword`    | Зарезервированное языком слово                  | `if`, `for`             |
| `separator`  | Символы пунктуации                              | `{`, `(`, `;`           |
| `operator`   | Символы для обозначения операции над операндами | `+`, `<`, `=`           |
| `literal`    | Булевы, числовые, текстовые литералы            | `true`, `123`, `"text"` |
